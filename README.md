# Relation extraction on Rotowire dataset
The main code for data preprocessing and model training. We try to use BERT and Distil-BERT as encoder and some pre-training mothods such as tasks of word and digit mask prediction and digit table selection to improve the performance.
